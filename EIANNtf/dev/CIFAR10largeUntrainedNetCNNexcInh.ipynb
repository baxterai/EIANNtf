{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 Large Untrained Net CNN Exc Inh"
      ],
      "metadata": {
        "id": "Bejpr3-EW5q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derived from  https://keras.io/zh/examples/cifar10_cnn_tfaugment2d/"
      ],
      "metadata": {
        "id": "eTRKkHORa7GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, Lambda, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.src.utils.np_utils import to_categorical\n",
        "import os\n",
        "\n",
        "if K.backend() != 'tensorflow':\n",
        "    raise RuntimeError('This example can only run with the '\n",
        "                       'TensorFlow backend, '\n",
        "                       'because it requires TF-native augmentation APIs')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n"
      ],
      "metadata": {
        "id": "sLu2qh8atkwA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inhibitoryNeuronOutputPositive = True\n",
        "if(inhibitoryNeuronOutputPositive):\n",
        "    inhibitoryNeuronSwitchActivation = True\n",
        "else:\n",
        "    inlineImplementation = False\t#False: only implementation  #True: excitatory/inhibitory neurons are on same sublayer, False: add inhibitory neurons to separate preceding sublayer\n",
        "    if(not inlineImplementation):\n",
        "        positiveWeightImplementation = False    #False: only current coded implementation\n",
        "        inhibitoryNeuronNormalisationFactorStatic = False    #True: normalise intermediary inhibitory neuron layer based on h0/h1 num neurons, False: normalise based on h0/h1 activations\n",
        "        excitatoryNeuronThreshold = 0.0   #orig: 0.0\n",
        "\n",
        "useSparsity = False\n",
        "if(useSparsity):\n",
        "  sparsityProbabilityOfConnection = 0.1 #1-sparsity\n",
        "#addSkipLayers = False  #skip layers not supported by keras model.add definition format\n",
        "\n",
        "inputLayerExcitatoryOnly = True #True: only current coded implementation\n",
        "\n",
        "generateUntrainedNetwork = False\n",
        "if(generateUntrainedNetwork):\n",
        "    numberOfHiddenLayers = 2  #default = 2, if 0 then useSVM=True\n",
        "    preFinalDenseLayer = False\n",
        "else:\n",
        "    numberOfHiddenLayers = 2  #default = 4, if 0 then useSVM=True\n",
        "    preFinalDenseLayer = False\n",
        "\n",
        "\n",
        "if(numberOfHiddenLayers > 1):\n",
        "    addSkipLayers = False   #optional\n",
        "else:\n",
        "    addSkipLayers = False   #mandatory\n",
        "\n",
        "layerSizeBase = 32  #default: 32\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 5  #100\n",
        "\n",
        "debugNoEIneurons = False\n",
        "debugPreTrainWeights = True\n",
        "debugPreTrainOutputs = True\n",
        "debugPostTrainWeights = True\n",
        "debugPostTrainOutputs = True\n",
        "if(debugNoEIneurons):\n",
        "    numberOfHiddenLayers = 4  #default = 4, if 0 then useSVM=True\n",
        "    preFinalDenseLayer = True"
      ],
      "metadata": {
        "id": "oEK0GMrRI6mp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(generateUntrainedNetwork):\n",
        "    #only train the last layer\n",
        "    generateLargeNetwork = True\n",
        "else:\n",
        "    generateLargeNetwork = False\n",
        "\n",
        "if(generateLargeNetwork):\n",
        "    largeNetworkRatio = 10    #100\n",
        "    generateLargeNetworkExpansion = False\n",
        "    if(generateLargeNetworkExpansion):\n",
        "        generateLargeNetworkRatioExponential = False\n",
        "else:\n",
        "    generateLargeNetworkRatio = False\n",
        "    largeNetworkRatio = 1\n",
        "\n",
        "def getLayerRatio(layerIndex):\n",
        "    layerRatio = 1\n",
        "    if(generateLargeNetwork):\n",
        "        if(generateLargeNetworkExpansion):\n",
        "            if(generateLargeNetworkRatioExponential):\n",
        "                layerRatio = largeNetworkRatio**layerIndex\n",
        "            else:\n",
        "                layerRatio = largeNetworkRatio * layerIndex\n",
        "        else:\n",
        "            layerRatio = largeNetworkRatio\n",
        "    else:\n",
        "        layerRatio = 1\n",
        "    return int(layerRatio)\n"
      ],
      "metadata": {
        "id": "UEWRDsS0l6FD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kernelInitializerWithSparsity(shape, dtype=None):\n",
        "    initialisedWeights = tf.random.normal(shape, dtype=dtype) #change to glorot_uniform?\n",
        "    sparsityMatrixMask = tf.random.uniform(shape, minval=0.0, maxval=1.0, dtype=tf.dtypes.float32)\n",
        "    sparsityMatrixMask = tf.math.less(sparsityMatrixMask, sparsityProbabilityOfConnection)\n",
        "    sparsityMatrixMask = tf.cast(sparsityMatrixMask, dtype=tf.dtypes.float32)\n",
        "    initialisedWeights = tf.multiply(initialisedWeights, sparsityMatrixMask)\n",
        "    return initialisedWeights\n",
        "\n",
        "if(useSparsity):\n",
        "     kernelInitializer = kernelInitializerWithSparsity\n",
        "else:\n",
        "    kernelInitializer = 'glorot_uniform'"
      ],
      "metadata": {
        "id": "ka3S7M_QmcQI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "J6NtP4obXJAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "num_predictions = 20\n",
        "save_dir = '/tmp/saved_models'\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
        "print(\"input_shape = \", input_shape)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "YrF_byEsXR3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd635d40-d134-49ab-d805-4eb6048fb043"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "input_shape =  (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "CD-57omeXMe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EIactivation(Z):\n",
        "    A = K.maximum(Z, excitatoryNeuronThreshold)-excitatoryNeuronThreshold  #ReLU\n",
        "    return A\n",
        "\n",
        "def EIactivationExcitatory(Z):\n",
        "    if(inlineImplementation):\n",
        "        if(positiveWeightImplementation):\n",
        "            return EIactivation(Z)\n",
        "        else:\n",
        "             print(\"EIactivationExcitatory error: requires positiveWeightImplementation\")\n",
        "    else:\n",
        "        print(\"EIactivationExcitatory error: requires inlineImplementation\")\n",
        "\n",
        "def EIactivationInhibitory(Z):\n",
        "    if(inlineImplementation):\n",
        "        if(positiveWeightImplementation):\n",
        "            return -EIactivation(Z)   #ReLU with negative output\n",
        "        else:\n",
        "             print(\"EIactivationInhibitory error: requires positiveWeightImplementation\")\n",
        "    else:\n",
        "        print(\"inlineImplementation error: requires inlineImplementation\")\n",
        "\n",
        "def EIweightInitializer(shape, dtype=None):\n",
        "    if(inlineImplementation):\n",
        "        if(positiveWeightImplementation):\n",
        "            w = tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "        else:\n",
        "            if(integrateWeights):\n",
        "                if(integrateWeightsInitialiseZero):\n",
        "                    w = tf.zeros(shape, dtype=dtype)    #tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "                else:\n",
        "                    #print(\"shape = \", shape)\n",
        "                    w = tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "                    wEIsize = w.shape[2]//2\n",
        "                    wSignE = tf.ones([w.shape[0], w.shape[1], wEIsize, w.shape[3]])\n",
        "                    wSignI = tf.ones([w.shape[0], w.shape[1], wEIsize, w.shape[3]])\n",
        "                    wSignI = tf.multiply(wSignI, -1)\n",
        "                    wSign = tf.concat([wSignE, wSignI], axis=2)\n",
        "                    w = tf.multiply(w, wSign)\n",
        "            else:\n",
        "                print(\"EIweightInitializer error: requires !positiveWeightImplementation:integrateWeights\")\n",
        "    else:\n",
        "        print(\"EIweightInitializer error: requires inlineImplementation\")\n",
        "\n",
        "    return w\n",
        "\n",
        "def EIweightInitializerExcitatory(shape, dtype=None):\n",
        "    if(positiveWeightImplementation):\n",
        "        print(\"EIweightInitializerExcitatory error: requires !positiveWeightImplementation\")\n",
        "    else:\n",
        "        return tf.math.abs(tf.random.normal(shape, dtype=dtype))\n",
        "\n",
        "def EIweightInitializerInhibitory(shape, dtype=None):\n",
        "    if(positiveWeightImplementation):\n",
        "        print(\"EIweightInitializerExcitatory error: requires !positiveWeightImplementation\")\n",
        "    else:\n",
        "        return tf.math.negative(tf.math.abs(tf.random.normal(shape, dtype=dtype)))\n",
        "\n",
        "def EIweightInitialisedAverage(shape):\n",
        "    return tf.reduce_mean(tf.math.abs(tf.random.normal(shape)))\n",
        "\n",
        "class negative(tf.keras.constraints.Constraint):\n",
        "    #based on https://www.tensorflow.org/api_docs/python/tf/keras/constraints/Constraint\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def __call__(self, w):\n",
        "        return w * tf.cast(tf.math.less_equal(w, 0.), w.dtype)\n",
        "\n",
        "class positiveOrNegative(tf.keras.constraints.Constraint):\n",
        "    #based on https://www.tensorflow.org/api_docs/python/tf/keras/constraints/Constraint\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def __call__(self, w):\n",
        "        w_shape = w.shape\n",
        "        #print(\"w_shape = \", w_shape)\n",
        "        wEIsize = w.shape[2]//2\n",
        "        wE = w[:, :, 0:wEIsize]\n",
        "        wI = w[:, :, wEIsize:]\n",
        "        wEcheck = tf.greater_equal(wE, 0)\n",
        "        wIcheck = tf.less_equal(wI, 0)\n",
        "        wEcheck = tf.cast(wEcheck, tf.float32)\n",
        "        wIcheck = tf.cast(wIcheck, tf.float32)\n",
        "        wE = tf.multiply(wE, wEcheck)\n",
        "        wI = tf.multiply(wI, wIcheck)\n",
        "        w = tf.concat([wE, wI], axis=2)\n",
        "        return w"
      ],
      "metadata": {
        "id": "BTzqrhsfk7mG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if(not inhibitoryNeuronOutputPositive):\n",
        "    if(not inlineImplementation):\n",
        "        EIweightConstraintPositive = tf.keras.constraints.non_neg()\n",
        "        EIweightConstraintNegative = negative()\n",
        "        constrainBiases = False\n",
        "        if(constrainBiases):\n",
        "            EIbiasConstraintPositive = tf.keras.constraints.non_neg()\n",
        "            EIbiasConstraintNegative = negative()\n",
        "        else:\n",
        "            EIbiasConstraintPositive = None\n",
        "            EIbiasConstraintNegative = None\n",
        "        EIweightConstraintLastLayer = None\n",
        "        EIbiasConstraintLastLayer = None\n",
        "\n",
        "\n",
        "def createEIlayer(layerIndex, h0, numChannels, previousNumChannels, firstLayer=False, maxpool2d=None, dropout=None):\n",
        "    layerRatio = getLayerRatio(2)\n",
        "    if(debugNoEIneurons):\n",
        "        h1 = tf.keras.layers.Conv2D(numChannels, (3,3), padding='same')(h0)\n",
        "        h1 = tf.keras.layers.Activation(EIactivation)(h1)\n",
        "        if(maxpool2d is not None):\n",
        "            h1 = tf.keras.layers.MaxPool2D(pool_size=maxpool2d)(h1)\n",
        "        if(dropout is not None):\n",
        "            h1 = tf.keras.layers.Dropout(dropout)(h1)\n",
        "    else:\n",
        "        if(inhibitoryNeuronOutputPositive):\n",
        "            h1E = tf.keras.layers.Conv2D(numChannels, (5,5), padding='same')(h0)\n",
        "            h1I = tf.keras.layers.Conv2D(numChannels, (5,5), padding='same')(h0)\n",
        "            h1E = tf.keras.layers.Activation('relu')(h1E)\n",
        "            if(inhibitoryNeuronSwitchActivation):\n",
        "                h1I = tf.keras.layers.Activation('relu')(-h1I)\n",
        "            else:\n",
        "                h1I = tf.keras.layers.Activation('relu')(h1I)\n",
        "            h1 = tf.keras.layers.Concatenate()([h1E, h1I])\n",
        "            if(maxpool2d is not None):\n",
        "                h1 = tf.keras.layers.MaxPool2D(pool_size=maxpool2d)(h1)\n",
        "            if(dropout is not None):\n",
        "                h1 = tf.keras.layers.Dropout(dropout)(h1)\n",
        "        else:\n",
        "            if(not inlineImplementation):\n",
        "                h1I = tf.keras.layers.Conv2D(previousNumChannels, (5,5), padding='same', kernel_initializer=EIweightInitializerExcitatory, kernel_constraint=EIweightConstraintPositive, bias_constraint=EIbiasConstraintPositive)(h0) #inhibitory interneuron (excitatory inputs)\n",
        "                if(not inhibitoryNeuronNormalisationFactorStatic):  #disabled because modifies activation levels\n",
        "                    h1I = tf.keras.layers.Activation(EIactivation)(h1I)\n",
        "                h1I = h1I*calculateInhibitoryNeuronNormalisationFactor(h0, h1I, numChannels, previousNumChannels, firstLayer)\n",
        "                h1Ee = tf.keras.layers.Conv2D(numChannels, (5,5), padding='same', kernel_initializer=EIweightInitializerExcitatory, kernel_constraint=EIweightConstraintPositive, bias_constraint=EIbiasConstraintPositive)(h0) #excitatory neuron excitatory inputs\n",
        "                h1Ei = tf.keras.layers.Conv2D(numChannels, (5,5), padding='same', kernel_initializer=EIweightInitializerInhibitory, kernel_constraint=EIweightConstraintNegative, bias_constraint=EIbiasConstraintNegative)(h1I) #excitatory neuron inhibitory inputs\n",
        "                h1E = tf.keras.layers.Add()([h1Ee, h1Ei])\n",
        "                h1E = tf.keras.layers.Activation(EIactivation)(h1E)\n",
        "                h1 = h1E\n",
        "    return h1\n",
        "\n",
        "def calculateAverageWeight(numChannels, previousNumChannels):\n",
        "    shape = [previousNumChannels,numChannels]\n",
        "    averageWeight = EIweightInitialisedAverage(shape)\n",
        "    #avg = x*sqrt(pi/2) = 1.25331413732 #https://stats.stackexchange.com/questions/363240/mean-of-absgauss-as-a-function-of-the-standard-deviation\n",
        "    return averageWeight\n",
        "\n",
        "def calculateInhibitoryNeuronNormalisationFactor(h0, h1I, numChannels, previousNumChannels, firstLayer=False):\n",
        "    if(inhibitoryNeuronNormalisationFactorStatic):\n",
        "        previousNumChannels = previousNumChannels*input_shape[1]*input_shape[2]\n",
        "        numChannels = numChannels*input_shape[1]*input_shape[2]\n",
        "        averageLayerActivation = 0.5    #this is not correct\n",
        "        averageWeight = calculateAverageWeight(numChannels, previousNumChannels)\n",
        "        if(firstLayer):\n",
        "            #assume input layer unequal activation/nonactivation level\n",
        "            averageLayerActivation = np.mean(x_train)\n",
        "        print(\"previousNumChannels = \", previousNumChannels)\n",
        "        print(\"averageLayerActivation = \", averageLayerActivation)\n",
        "        print(\"averageWeight = \", averageWeight)\n",
        "        h1InormalisationFactor = (1/previousNumChannels*averageWeight)*averageLayerActivation\n",
        "    else:\n",
        "        h1InormalisationFactor = tf.reduce_mean(h0)/tf.reduce_mean(h1I)\n",
        "    return h1InormalisationFactor\n",
        "\n",
        "def concatEIneurons(h):\n",
        "    if(inhibitoryNeuronOutputPositive):\n",
        "        return h\n",
        "    else:\n",
        "        if(inlineImplementation):\n",
        "            if(positiveWeightImplementation):\n",
        "                return h\n",
        "            else:\n",
        "                if(integrateWeights):\n",
        "                    pass\n",
        "                else:\n",
        "                    hE, hI = h\n",
        "                    h = tf.keras.layers.Concatenate()([hE, hI])\n",
        "                return h\n",
        "        else:\n",
        "            return h\n"
      ],
      "metadata": {
        "id": "rbQehxeOlom9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Input(shape=input_shape)\n",
        "h0 = x\n",
        "hLast = h0\n",
        "\n",
        "previousNumChannels = input_shape[2]   #3\n",
        "if(numberOfHiddenLayers >= 1):\n",
        "    numChannels = layerSizeBase*1*getLayerRatio(1)\n",
        "    h1 = createEIlayer(1, h0, numChannels, previousNumChannels, firstLayer=True)\n",
        "    hLast = h1\n",
        "    previousNumChannels = numChannels\n",
        "if(numberOfHiddenLayers >= 2):\n",
        "    numChannels = layerSizeBase*1*getLayerRatio(2)\n",
        "    h2 = createEIlayer(2, h1, numChannels, previousNumChannels, maxpool2d=(2,2), dropout=0.25)\n",
        "    hLast = h2\n",
        "    previousNumChannels = numChannels\n",
        "if(numberOfHiddenLayers >= 3):\n",
        "    numChannels = layerSizeBase*2*getLayerRatio(3)\n",
        "    h3 = createEIlayer(3, h2, numChannels, previousNumChannels)\n",
        "    hLast = h3\n",
        "    previousNumChannels = numChannels\n",
        "if(numberOfHiddenLayers >= 4):\n",
        "    numChannels = layerSizeBase*2*getLayerRatio(4)\n",
        "    h4 = createEIlayer(4, h3, numChannels, previousNumChannels, maxpool2d=(2,2), dropout=0.25)\n",
        "    hLast = h4\n",
        "    previousNumChannels = numChannels\n",
        "\n",
        "if(addSkipLayers):\n",
        "    mList = []\n",
        "    if(numberOfHiddenLayers >= 1):\n",
        "        m1 = tf.keras.layers.Flatten()(concatEIneurons(h1))\n",
        "        mList.append(m1)\n",
        "    if(numberOfHiddenLayers >= 2):\n",
        "        m2 = tf.keras.layers.Flatten()(concatEIneurons(h2))\n",
        "        mList.append(m2)\n",
        "    if(numberOfHiddenLayers >= 3):\n",
        "        m3 = tf.keras.layers.Flatten()(concatEIneurons(h3))\n",
        "        mList.append(m3)\n",
        "    if(numberOfHiddenLayers >= 4):\n",
        "        m4 = tf.keras.layers.Flatten()(concatEIneurons(h4))\n",
        "        mList.append(m4)\n",
        "    hLast = tf.keras.layers.concatenate(mList)\n",
        "else:\n",
        "    hLast = concatEIneurons(hLast)\n",
        "\n",
        "hLast = tf.keras.layers.Flatten()(hLast)\n",
        "if(preFinalDenseLayer):\n",
        "    numChannels = 512*largeNetworkRatio\n",
        "    hLast = tf.keras.layers.Dense(numChannels, activation='relu', kernel_initializer=kernelInitializer)(hLast)\n",
        "    hLast = tf.keras.layers.Dropout(0.5)(hLast)\n",
        "\n",
        "if(generateUntrainedNetwork):\n",
        "    hLast = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stop_gradient(x))(hLast)\n",
        "\n",
        "y = tf.keras.layers.Dense(num_classes, activation='softmax')(hLast)\n",
        "model = tf.keras.Model(x, y)"
      ],
      "metadata": {
        "id": "lxYn4_sNXSWT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())\n",
        "#printModelSummary(model)\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(epsilon=1e-08)\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
        "    #orig: model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDgh_ednvcTg",
        "outputId": "0e97d4bb-c552-4904-f225-41585fb7e38a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)           2432      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)           2432      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.negative (TFOpLamb  (None, 32, 32, 32)           0         ['conv2d_1[0][0]']            \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 32)           0         ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 32)           0         ['tf.math.negative[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 64)           0         ['activation[0][0]',          \n",
            "                                                                     'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)           51232     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)           51232     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.negative_1 (TFOpLa  (None, 32, 32, 32)           0         ['conv2d_3[0][0]']            \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 32, 32, 32)           0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 32, 32, 32)           0         ['tf.math.negative_1[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 32, 32, 64)           0         ['activation_2[0][0]',        \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 64)           0         ['concatenate_1[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 16, 16, 64)           0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 16384)                0         ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   163850    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 271178 (1.03 MB)\n",
            "Trainable params: 271178 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "VdTSQEW7XO23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(debugPreTrainWeights):\n",
        "    testwritefile = open('weightsPreTrain.txt', 'w')\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"\\n\" + \"layer = \" + str(layerIndex) + \"\\n\"\n",
        "        testwritefile.write(heading)\n",
        "        weights = layer.get_weights()\n",
        "        #weightsAvg = np.mean(weights[0])\n",
        "        #print(heading)\n",
        "        #print(weights)\n",
        "        weightsS =  str(weights)\n",
        "        testwritefile.write(weightsS)\n",
        "    testwritefile.close()"
      ],
      "metadata": {
        "id": "sCuL6Bu_ENL2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(debugPreTrainOutputs):\n",
        "    testwritefile = open('outputPreTrain.txt', 'w')\n",
        "    xTrainFirstSample = np.expand_dims(x_train[0], axis=0)\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"\\n\" + \"layer = \" + str(layerIndex) + \"\\n\"\n",
        "        testwritefile.write(heading)\n",
        "        func = K.function([model.get_layer(index=0).input], layer.output)\n",
        "        layerOutput = func([xTrainFirstSample])  # input_data is a numpy array\n",
        "        #print(heading)\n",
        "        #print(layerOutput)\n",
        "        layerOutputS =  str(layerOutput)\n",
        "        testwritefile.write(layerOutputS)\n",
        "    testwritefile.close()"
      ],
      "metadata": {
        "id": "RSHi3FBAEOvL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "nMOIUGUvXSz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be94f075-429a-450e-bc08-6f1f4c726a5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 95s 60ms/step - loss: 1.4598 - acc: 0.4876 - val_loss: 1.3084 - val_acc: 0.5517\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 96s 62ms/step - loss: 1.1271 - acc: 0.6166 - val_loss: 1.1035 - val_acc: 0.6238\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 1.0251 - acc: 0.6505 - val_loss: 1.0692 - val_acc: 0.6328\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 96s 61ms/step - loss: 0.9700 - acc: 0.6743 - val_loss: 1.0493 - val_acc: 0.6345\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 0.9191 - acc: 0.6905 - val_loss: 1.1481 - val_acc: 0.6063\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)           2432      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)           2432      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.negative (TFOpLamb  (None, 32, 32, 32)           0         ['conv2d_1[0][0]']            \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 32)           0         ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 32)           0         ['tf.math.negative[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 64)           0         ['activation[0][0]',          \n",
            "                                                                     'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)           51232     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)           51232     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.negative_1 (TFOpLa  (None, 32, 32, 32)           0         ['conv2d_3[0][0]']            \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 32, 32, 32)           0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 32, 32, 32)           0         ['tf.math.negative_1[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 32, 32, 64)           0         ['activation_2[0][0]',        \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 64)           0         ['concatenate_1[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 16, 16, 64)           0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 16384)                0         ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   163850    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 271178 (1.03 MB)\n",
            "Trainable params: 271178 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(debugPostTrainWeights):\n",
        "    testwritefile = open('weightsPostTrain.txt', 'w')\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"\\n\" + \"layer = \" + str(layerIndex) + \"\\n\"\n",
        "        testwritefile.write(heading)\n",
        "        weights = layer.get_weights()\n",
        "        #print(heading)\n",
        "        #print(weights)\n",
        "        weightsS =  str(weights)\n",
        "        testwritefile.write(weightsS)\n",
        "    testwritefile.close()"
      ],
      "metadata": {
        "id": "LnvEsT0kER7a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(debugPostTrainOutputs):\n",
        "    testwritefile = open('outputPostTrain.txt', 'w')\n",
        "    xTrainFirstSample = np.expand_dims(x_train[0], axis=0)\n",
        "    for layerIndex, layer in enumerate(model.layers):\n",
        "        heading = \"\\n\" + \"layer = \" + str(layerIndex) + \"\\n\"\n",
        "        testwritefile.write(heading)\n",
        "        func = K.function([model.get_layer(index=0).input], layer.output)\n",
        "        layerOutput = func([xTrainFirstSample])  # input_data is a numpy array\n",
        "        #print(heading)\n",
        "        #print(layerOutput)\n",
        "        layerOutputS =  str(layerOutput)\n",
        "        testwritefile.write(layerOutputS)\n",
        "    testwritefile.close()"
      ],
      "metadata": {
        "id": "kX8x6p_uETlj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "Rkx9nThzXQkP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HEHJ0qXiDd0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0373f0c-869a-4bab-ce6f-ffebd39f39d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 1.1481 - acc: 0.6063\n",
            "Test loss: 1.1481282711029053\n",
            "Test accuracy: 0.6062999963760376\n"
          ]
        }
      ],
      "source": [
        "# Save model and weights\n",
        "#if not os.path.isdir(save_dir):\n",
        "#    os.makedirs(save_dir)\n",
        "#model_path = os.path.join(save_dir, model_name)\n",
        "#model.save(model_path)\n",
        "#print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    }
  ]
}